{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14202d5-0717-4c75-a273-ee719bd947c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Downloading groq-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain_groq)\n",
      "  Downloading langchain_core-0.3.17-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.10.12)\n",
      "Requirement already satisfied: sniffio in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (6.0.1)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.15->langchain_groq)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4.0,>=0.3.15->langchain_groq)\n",
      "  Downloading langsmith-0.1.142-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.15->langchain_groq)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from groq<1,>=0.4.1->langchain_groq)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (8.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_groq) (2.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq)\n",
      "  Downloading orjson-3.10.11-cp311-none-win_amd64.whl.metadata (52 kB)\n",
      "     ---------------------------------------- 0.0/52.0 kB ? eta -:--:--\n",
      "     -------------------------------------  51.2/52.0 kB 871.5 kB/s eta 0:00:01\n",
      "     -------------------------------------- 52.0/52.0 kB 663.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (1.0.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq)\n",
      "  Downloading pydantic_core-2.23.4-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (2.0.7)\n",
      "Downloading langchain_groq-0.2.1-py3-none-any.whl (14 kB)\n",
      "Downloading groq-0.12.0-py3-none-any.whl (108 kB)\n",
      "   ---------------------------------------- 0.0/108.9 kB ? eta -:--:--\n",
      "   -------------- ------------------------ 41.0/108.9 kB 960.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 102.4/108.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 108.9/108.9 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.17-py3-none-any.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.3 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 92.2/409.3 kB 2.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 112.6/409.3 kB 2.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 174.1/409.3 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 225.3/409.3 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 327.7/409.3 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 409.3/409.3 kB 1.5 MB/s eta 0:00:00\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.1.142-py3-none-any.whl (306 kB)\n",
      "   ---------------------------------------- 0.0/306.7 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 112.6/306.7 kB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 245.8/306.7 kB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 297.0/306.7 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 306.7/306.7 kB 2.1 MB/s eta 0:00:00\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.9 MB 8.3 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.1/1.9 MB 8.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/1.9 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.7/1.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 2.2 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading orjson-3.10.11-cp311-none-win_amd64.whl (136 kB)\n",
      "   ---------------------------------------- 0.0/136.4 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 61.4/136.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 136.4/136.4 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pydantic-core, packaging, orjson, jsonpatch, annotated-types, pydantic, langsmith, groq, langchain-core, langchain_groq\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.12\n",
      "    Uninstalling pydantic-1.10.12:\n",
      "      Successfully uninstalled pydantic-1.10.12\n",
      "Successfully installed annotated-types-0.7.0 groq-0.12.0 jsonpatch-1.33 langchain-core-0.3.17 langchain_groq-0.2.1 langsmith-0.1.142 orjson-3.10.11 packaging-24.2 pydantic-2.9.2 pydantic-core-2.23.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_groq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d38cc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement langchain_community.document_loaders (from versions: none)\n",
      "ERROR: No matching distribution found for langchain_community.document_loaders\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community.document_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24255260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain) (0.3.17)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain) (0.1.142)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (2.1)\n",
      "Downloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.0 MB 1.3 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.1/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.2/1.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.3/1.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.3/1.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.3/1.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.3/1.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.3/1.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.3/1.0 MB 1.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.4/1.0 MB 859.0 kB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.4/1.0 MB 895.2 kB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.5/1.0 MB 861.1 kB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.5/1.0 MB 850.4 kB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.6/1.0 MB 894.6 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.7/1.0 MB 967.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 0.9/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 0.9/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 0.9/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 0.9/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 0.9/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 0.9/1.0 MB 931.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.0/1.0 MB 909.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.0/1.0 MB 909.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.0/1.0 MB 909.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.0/1.0 MB 909.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 794.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 786.2 kB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: langchain-text-splitters, langchain\n",
      "Successfully installed langchain-0.3.7 langchain-text-splitters-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73fb88e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain_community) (0.3.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain_community) (0.3.17)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.142)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain_community) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\deshr\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.4 MB 2.6 MB/s eta 0:00:01\n",
      "   - -------------------------------------- 0.1/2.4 MB 2.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.2/2.4 MB 1.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/2.4 MB 1.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 901.1 kB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.4/2.4 MB 890.4 kB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.5/2.4 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.7/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.8/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.0/2.4 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.1/2.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.2/2.4 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.4 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.5/2.4 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.5/2.4 MB 1.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.4 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.8/2.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.9/2.4 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.2/2.4 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 1.9 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.5/49.5 kB ? eta 0:00:00\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.7 marshmallow-3.23.1 pydantic-settings-2.6.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27dc07e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first person to land on the moon was Neil Armstrong. He stepped out of the lunar module Eagle and onto the moon's surface on July 20, 1969.\n",
      "\n",
      "The second person to walk on the moon was Edwin \"Buzz\" Aldrin. He joined Neil Armstrong on the moon's surface shortly after Armstrong's historic first steps.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    groq_api_key=\"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\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "response=llm.invoke(\"The first person to land on the moon was and who was second?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72f1eab-9344-488c-89d3-76515a026a31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Amazon University Talent Acquisition (AUTA)\n",
      "Skip to main contentHomeMy careerMy applicationsMy profileAccount securitySettingsSign outAmazon culture & benefitsDiversity at AmazonLocationsTeamsJob categoriesResourcesInterview tipsDisability accommodationsAbout AmazonFAQ× Amazon University TalentInfluence the Amazon of tomorrowAmazon internships and full-time roles for graduates give you the opportunity to solve problems, innovate on behalf of our customers, and shape our business.Find open university rolesAboutDesign your careerAt Amazon, your career will grow in new and exciting directions—designed by you. You’ll have the opportunity to be part of innovative projects, lead initiatives, and take ownership and responsibility.Here, you’ll work with groundbreaking technology and learn from the best all over the world, united with the common goal to delight our customers.Our internship roles for students, and our full-time roles for graduates, give you the chance to make a real impact on the lives of millions.Internships for studentsFull-time roles for graduatesFeatured programsSpecialized student opportunitiesOperations opportunities for studentsUse innovative technologies to support customers through our global network of fulfillment centers and delivery stations.AWS internshipsExplore the cloud industry and build real-world skills and connections with AWS.Amazon PathwaysReach senior levels within Amazon Operations with the Pathways Operations Leadership Program. MBA or higher.TestimonialsHear from recent Amazon internsComing into Amazon as an intern, I’ve seen the most talented people who inspire me to be better, want to improve, and do what I do every day.EdwardSoftware Development EngineerThere’s no typical day at Amazon, and that’s what I love about it most. Here, I’m given the flexibility to create processes that directly help people.RiaProgram ManagerI’m looking forward to contributing to Amazon’s mission and making a positive impact in the industry. I’m eager to have an enriching learning experience of six months, which will be a fantastic head start for my career.PratikSDE internPerspectivesBuild the future at AmazonLove your workDownload video transcriptShreya, from intern to software engineer.A day in the lifeDownload video transcriptSpend a day with Kazeem.Path to successDownload video transcriptEdward, intern turned software development engineer.Join the Amazon university talent community.Interested in student opportunities at Amazon? Sign up today and we’ll keep you posted on relevant roles and how to apply.Join our University Talent Network JOIN US ONFind CareersJob CategoriesTeamsLocationsUS and EU Military recruitingWarehouse and Hourly JobsWorking At AmazonCultureBenefitsAmazon NewsletterDiversity at AmazonOur leadership principlesHelpFAQInterview tipsReview application statusDisability accommodationsEU background checksAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.Privacy and DataImpressum© 1996-2024, Amazon.com, Inc. or its affiliates\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.amazon.jobs/content/en/career-programs/university\")\n",
    "page_data=loader.load().pop().page_content\n",
    "print(page_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fcb5e13-e7f8-4ad1-aaa1-8bf1d76001ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"role\": \"Software Engineer\",\n",
      "    \"experience\": \"3-5 years\",\n",
      "    \"skills\": [\"Java\", \"Spring Boot\", \"MySQL\"],\n",
      "    \"description\": \"We are looking for a skilled Software Engineer to join our team. The ideal candidate will have experience in Java, Spring Boot, and MySQL. Responsibilities include designing, developing, and testing software applications.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"Data Scientist\",\n",
      "    \"experience\": \"2-4 years\",\n",
      "    \"skills\": [\"Python\", \"Machine Learning\", \"Data Visualization\"],\n",
      "    \"description\": \"We are seeking a Data Scientist to analyze and interpret complex data to inform business decisions. The ideal candidate will have experience in Python, Machine Learning, and Data Visualization.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"DevOps Engineer\",\n",
      "    \"experience\": \"4-6 years\",\n",
      "    \"skills\": [\"AWS\", \"Docker\", \"Kubernetes\"],\n",
      "    \"description\": \"We are looking for a DevOps Engineer to join our team. The ideal candidate will have experience in AWS, Docker, and Kubernetes. Responsibilities include designing, implementing, and maintaining our cloud infrastructure.\"\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ###SCRAPED TEXT FROM WEBSITE\n",
    "    {page_data}\n",
    "    ###INSTRUCTION:\n",
    "    you scraped text from the carrer's page of a website.\n",
    "    your job is to extract the job postings and return them in json format\n",
    "    containing following keys:`role`,`experience`,`skills` and `description`.\n",
    "    Only return the valid JSON.\n",
    "    ###VALID JSON (NO PREAMBLE)\"\"\"\n",
    ")\n",
    "chain_extract=prompt_extract | llm\n",
    "res=chain_extract.invoke(input={'page_data'})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "849376be-e78c-4dc4-9b50-2179ce99295c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Data Scientist',\n",
       " 'experience': '2-4 years',\n",
       " 'skills': ['Python', 'Machine Learning', 'Data Visualization'],\n",
       " 'description': 'We are seeking a Data Scientist to analyze and interpret complex data to inform business decisions. The ideal candidate will have experience in Python, Machine Learning, and Data Visualization.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "json_parser=JsonOutputParser()\n",
    "json_res=json_parser.parse(res.content)\n",
    "json_res=json_res[1]\n",
    "json_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6adca70-f2be-4f6e-9fb6-ec7cb8389184",
   "metadata": {},
   "source": [
    "########ADDING THE RESUME PART###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d3934c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHUBHAM BAGHEL\n",
      "NIT KKR AIML’27 \n",
      "\n",
      "C O N T A C T\n",
      "\n",
      "P R O F I L E\n",
      "\n",
      "+91 8307489623\n",
      "\n",
      "123108022@nitkkr.ac.in\n",
      "\n",
      "Vikas Nagar, Rewari,\n",
      "Haryana\n",
      "\n",
      "Passionate  AI  Engineering  Student  currently  studying  in  2nd  year  at  NIT\n",
      "Kurukshetra, with a strong focus on machine learning, deep learning, and data\n",
      "analysis. Proficient in Python, Java, HTML, CSS, and JavaScript, with hands-on\n",
      "experience  in  Django.  Demonstrated  expertise  through  coursework  and\n",
      "projects, including a Jarvis-like virtual assistant. Adept at utilizing modern tools\n",
      "and technologies for innovative solutions. Eager to apply skills and knowledge\n",
      "in data science and AI to contribute effectively in a professional environment.\n",
      "\n",
      "E D U C A T I O N\n",
      "\n",
      "2023-27\n",
      "\n",
      "COLLEGE-NIT KURUKSHETRA\n",
      "\n",
      "B-Tech in Artificial\n",
      "\n",
      "intelligence and Machine\n",
      "\n",
      "learning\n",
      "\n",
      "SCHOOL-RPS GROUP OF\n",
      "\n",
      "SCHOOLS\n",
      "\n",
      "90% in class 12th\n",
      "\n",
      "S K I L L S\n",
      "\n",
      "Machine Learning\n",
      "\n",
      "Microsoft Azure\n",
      "\n",
      "Python Programming\n",
      "\n",
      "Python(proficient)\n",
      "\n",
      "C-programming(proficient)\n",
      "\n",
      "Django\n",
      "\n",
      "SQL\n",
      "\n",
      "Data structures in C\n",
      "\n",
      "java(Beginner )\n",
      "\n",
      "W O R K   E X P E R I E N C E\n",
      "\n",
      "Jarvis-like Virtual Assistant\n",
      "\n",
      "Developed a virtual assistant using Python and Django with the use of\n",
      "basic python programming with Google’Gemini API .\n",
      "Enhanced  user  experience  with  Django  by  making  user  friendly\n",
      "interface\n",
      "\n",
      "Machine  Learning\n",
      "\n",
      "Supervised  machine  learning  Specialization  by  Stanford  online  and\n",
      "deeplearning.ai on Coursera  \n",
      "Applied  knowledge  to  practical  projects  (house  price  prediction  and\n",
      "cancer detection)\n",
      "\n",
      "Microsoft Azure\n",
      "\n",
      "Computer  Vision:  Implemented  image  classification  models  using\n",
      "Azure  Computer  Vision  tools,  achieving  high  accuracy  in  identifying\n",
      "and categorizing images.\n",
      "Natural  Language  Processing  (NLP):  Developed  NLP  solutions\n",
      "leveraging  Azure  Cognitive  Services  for  text  analysis,  sentiment\n",
      "analysis, and language understanding.\n",
      "\n",
      "Django \n",
      "\n",
      "Built  an  E-commerce  website  by  using  Django  and  gained  good\n",
      "knowledge about the Django-admin \n",
      "\n",
      "C E R T I F I C A T I O N\n",
      "\n",
      "link=”https://www.coursera.org/account/accomplishments/verify/EA8F5C\n",
      "XJQDHW”\n",
      "\n",
      "L A N G U A G E S\n",
      "\n",
      "H O B B I E S   A N D   I N T R E S T S\n",
      "\n",
      "English (Fluent)\n",
      "Hindi\n",
      "\n",
      "Singing\n",
      "volleyball\n",
      "Badminton\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "from pdfminer import high_level  \n",
    "\n",
    "\n",
    "def extract_text_from_pdf(file_path):  \n",
    "    text = high_level.extract_text(file_path)  \n",
    "    return text  \n",
    "\n",
    "# Specify the path to your PDF file  \n",
    "file_path = 'Shubham_Resume.pdf'  \n",
    "\n",
    "# Extract text from the PDF file  \n",
    "resume_text = extract_text_from_pdf(file_path)  \n",
    "\n",
    "# Print the extracted text  \n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d70a0ac-c24e-4d6e-9cc4-372027a2ab8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'SHUBHAM BAGHEL', 'contact': {'phone': '+91 8307489623', 'email': '123108022@nitkkr.ac.in', 'address': 'Vikas Nagar, Rewari, Haryana'}, 'work_experience': [{'project': 'Jarvis-like Virtual Assistant', 'description': \"Developed a virtual assistant using Python and Django with the use of basic python programming with Google's Gemini API. Enhanced user experience with Django by making user-friendly interface.\"}, {'project': 'Machine Learning', 'description': 'Supervised machine learning Specialization by Stanford online and deeplearning.ai on Coursera. Applied knowledge to practical projects (house price prediction and cancer detection).'}, {'project': 'Microsoft Azure', 'description': 'Computer Vision: Implemented image classification models using Azure Computer Vision tools, achieving high accuracy in identifying and categorizing images. Natural Language Processing (NLP): Developed NLP solutions leveraging Azure Cognitive Services for text analysis, sentiment analysis, and language understanding.'}, {'project': 'Django', 'description': 'Built an E-commerce website by using Django and gained good knowledge about the Django-admin.'}], 'education': [{'institution': 'NIT Kurukshetra', 'degree': 'B-Tech in Artificial Intelligence and Machine Learning', 'duration': '2023-27'}, {'institution': 'RPS Group of Schools', 'degree': 'Class 12th', 'percentage': '90%'}], 'skills': ['Machine Learning', 'Microsoft Azure', 'Python Programming', 'Python (proficient)', 'C-programming (proficient)', 'Django', 'SQL', 'Data structures in C', 'Java (Beginner)']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Dict, List\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Assuming 'llm' is your initialized language model\n",
    "\n",
    "# 1. Parse resume text\n",
    "resume_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ###SCRAPED TEXT FROM RESUME PDF\n",
    "    {resume_text}\n",
    "    ###INSTRUCTION:\n",
    "    Extract key information from the resume and return it in JSON format\n",
    "    containing the following keys: `name`, `contact`, `Work experience`, `education`, `skills`.\n",
    "    Only return the valid JSON.\n",
    "    ###VALID JSON (NO PREAMBLE)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "resume_chain = resume_prompt | llm | JsonOutputParser()\n",
    "res=resume_chain.invoke(input={'resume_text': resume_text})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2573e89a-f069-44cd-8fe0-1c8e5fe4cd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'SHUBHAM BAGHEL', 'contact': {'email': '123108022@nitkkr.ac.in', 'phone': '+91 8307489623'}, 'education': [{'institution': 'NIT Kurukshetra', 'degree': 'B-Tech in Artificial Intelligence and Machine Learning', 'duration': '2023-27'}, {'institution': 'RPS GROUP OF SCHOOLS', 'degree': 'Class 12th', 'percentage': '90%'}], 'skills': ['Machine Learning', 'Microsoft Azure', 'Python Programming', 'Python', 'C-programming', 'Django', 'SQL', 'Data structures in C', 'Java'], 'workExperience': [{'project': 'Jarvis-like Virtual Assistant', 'description': 'Developed a virtual assistant using Python and Django with the use of basic python programming with Google’s Gemini API. Enhanced user experience with Django by making user-friendly interface.'}, {'project': 'Machine Learning', 'description': 'Supervised machine learning Specialization by Stanford online and deeplearning.ai on Coursera. Applied knowledge to practical projects (house price prediction and cancer detection).'}, {'project': 'Microsoft Azure', 'description': 'Computer Vision: Implemented image classification models using Azure Computer Vision tools, achieving high accuracy in identifying and categorizing images. Natural Language Processing (NLP): Developed NLP solutions leveraging Azure Cognitive Services for text analysis, sentiment analysis, and language understanding.'}, {'project': 'Django', 'description': 'Built an E-commerce website by using Django and gained good knowledge about the Django-admin.'}], 'certifications': [{'link': 'https://www.coursera.org/account/accomplishments/verify/EA8F5CXJQDHW'}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Dict, List\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "resume_prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ###RESUME TEXT\n",
    "        {resume_text}\n",
    "        ###INSTRUCTION:\n",
    "        Extract and structure the following information from the resume:\n",
    "        1. Name\n",
    "        2. Contact (email and phone)\n",
    "        3. Education (including institution and degree)\n",
    "        4. Skills (as a list)\n",
    "        5. Work Experience (including project details)\n",
    "        6. Certifications\n",
    "        Return the structured information in JSON format.\n",
    "        ###VALID JSON (NO PREAMBLE)\n",
    "        \"\"\"\n",
    ")\n",
    "    \n",
    "resume_chain = resume_prompt | llm | JsonOutputParser()\n",
    "\n",
    "parsed_res=resume_chain.invoke(input={'resume_text': resume_text})\n",
    "print(parsed_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f66d2b-c329-415a-990f-7199b0938df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'Data Scientist', 'experience': '2-4 years', 'skills': ['Python', 'R', 'Machine Learning'], 'description': 'We are looking for a Data Scientist to join our team. The ideal candidate will have experience in Python and R, as well as experience with machine learning algorithms. The candidate will be responsible for analyzing and interpreting complex data sets.'}\n"
     ]
    }
   ],
   "source": [
    "#printing job details\n",
    "print(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "badf85a6-cedf-425c-a1f7-d1a113d0d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'SHUBHAM BAGHEL', 'contact': {'email': '123108022@nitkkr.ac.in', 'phone': '+91 8307489623'}, 'education': [{'institution': 'NIT Kurukshetra', 'degree': 'B-Tech in Artificial Intelligence and Machine Learning', 'duration': '2023-27'}, {'institution': 'RPS GROUP OF SCHOOLS', 'degree': 'Class 12th', 'percentage': '90%'}], 'skills': ['Machine Learning', 'Microsoft Azure', 'Python Programming', 'Python', 'C-programming', 'Django', 'SQL', 'Data structures in C', 'Java'], 'workExperience': [{'project': 'Jarvis-like Virtual Assistant', 'description': 'Developed a virtual assistant using Python and Django with the use of basic python programming with Google’s Gemini API. Enhanced user experience with Django by making user-friendly interface.'}, {'project': 'Machine Learning', 'description': 'Supervised machine learning Specialization by Stanford online and deeplearning.ai on Coursera. Applied knowledge to practical projects (house price prediction and cancer detection).'}, {'project': 'Microsoft Azure', 'description': 'Computer Vision: Implemented image classification models using Azure Computer Vision tools, achieving high accuracy in identifying and categorizing images. Natural Language Processing (NLP): Developed NLP solutions leveraging Azure Cognitive Services for text analysis, sentiment analysis, and language understanding.'}, {'project': 'Django', 'description': 'Built an E-commerce website by using Django and gained good knowledge about the Django-admin.'}], 'certifications': [{'link': 'https://www.coursera.org/account/accomplishments/verify/EA8F5CXJQDHW'}]}\n"
     ]
    }
   ],
   "source": [
    "#printing parsed resume\n",
    "print(parsed_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "083f49d7-a8a2-482f-bc9f-7e35e351a562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python', 'R', 'Machine Learning']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_skills=json_res['skills']\n",
    "job_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40579a8a-f59a-40bd-9a4a-2fdd87199f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Scientist'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobrole=json_res['role']\n",
    "jobrole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "749c7a81-b73f-4bcc-b352-ed2b29ecc836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine Learning',\n",
       " 'Microsoft Azure',\n",
       " 'Python Programming',\n",
       " 'Python',\n",
       " 'C-programming',\n",
       " 'Django',\n",
       " 'SQL',\n",
       " 'Data structures in C',\n",
       " 'Java']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_skills=parsed_res['skills']\n",
    "resume_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1bc2a56-62e1-408e-9f63-522ea24067d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_skills = list(set(job_skills + resume_skills))  # Combine and deduplicate job and resume skills\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f641f05-4344-435e-85b5-54423ca3224f",
   "metadata": {},
   "source": [
    "Skill Matching using sentence transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf29d7a2-7000-4954-98cb-1946f4cf8906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deshr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\deshr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed4925c2-7b33-4680-807d-b1121680ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_skills(job_skills, resume_skills, threshold=0.6):\n",
    "    # Initialize the model\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    \n",
    "    # Generate embeddings\n",
    "    job_embeddings = model.encode(job_skills)\n",
    "    resume_embeddings = model.encode(resume_skills)\n",
    "    \n",
    "    # Calculate similarity matrix\n",
    "    similarity_matrix = cosine_similarity(job_embeddings, resume_embeddings)\n",
    "    \n",
    "    # Match skills\n",
    "    matches = []\n",
    "    missing_skills = []\n",
    "    \n",
    "    for i, job_skill in enumerate(job_skills):\n",
    "        # Find best matching resume skill\n",
    "        best_match_idx = similarity_matrix[i].argmax()\n",
    "        best_match_score = similarity_matrix[i][best_match_idx]\n",
    "        \n",
    "        if best_match_score >= threshold:\n",
    "            matches.append({\n",
    "                'job_skill': job_skill,\n",
    "                'resume_skill': resume_skills[best_match_idx],\n",
    "                'similarity': best_match_score\n",
    "            })\n",
    "        else:\n",
    "            missing_skills.append(job_skill)\n",
    "    \n",
    "    return {\n",
    "        'matches': matches,\n",
    "        'missing_skills': missing_skills\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99b48879-1f86-423b-91df-457aed4e2fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deshr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matched Skills:\n",
      "Python -> Python (Similarity: 1.00)\n",
      "Machine Learning -> Machine Learning (Similarity: 1.00)\n",
      "\n",
      "Missing Skills:\n",
      "- R\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "results = match_skills(job_skills, resume_skills)\n",
    "print(\"\\nMatched Skills:\")\n",
    "for match in results['matches']:\n",
    "    print(f\"{match['job_skill']} -> {match['resume_skill']} (Similarity: {match['similarity']:.2f})\")\n",
    "\n",
    "print(\"\\nMissing Skills:\")\n",
    "for skill in results['missing_skills']:\n",
    "    print(f\"- {skill}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10144b2e-b732-4fd2-9a25-7fc06895e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from docx import Document\n",
    "from docx.shared import Pt, Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "import json\n",
    "import spacy\n",
    "from typing import Dict, List, Any\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86c72ced-8611-4bd7-98a2-5c419c2cb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's format the matched skills and job description properly\n",
    "matched_skills_list = [match['job_skill'] for match in results['matches']]\n",
    "missing_skills = results['missing_skills']\n",
    "\n",
    "# Format job description from json_res\n",
    "job_description = {\n",
    "    'role': json_res['role'],\n",
    "    'experience': json_res['experience'],\n",
    "    'required_skills': json_res['skills'],\n",
    "    'description': json_res['description']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d64495-a21b-485e-b839-eecc03089810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14e31968-8946-47d8-a080-a3837162b0de",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to PromptTemplate is missing variables {'job_description[experience]', 'job_description[description]', 'job_description[required_skills]', 'job_description[role]'}.  Expected: ['job_description[description]', 'job_description[experience]', 'job_description[required_skills]', 'job_description[role]', 'matched_skills', 'missing_skills', 'resume_text'] Received: ['resume_text', 'job_description', 'matched_skills', 'missing_skills']\\nNote: if you intended {job_description[experience]} to be part of the string and not a variable, please escape it with double curly braces like: '{{job_description[experience]}}'.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Now invoke the prompt with the correct variables\u001b[39;00m\n\u001b[0;32m     55\u001b[0m resume_enhancement \u001b[38;5;241m=\u001b[39m resume_enhancement_prompt \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m---> 56\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mresume_enhancement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresume_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjob_description\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatched_skills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatched_skills_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmissing_skills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmissing_skills\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(res\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2876\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2874\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   2875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2876\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2877\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2878\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\prompts\\base.py:186\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    185\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1785\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1782\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1783\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1784\u001b[0m         Output,\n\u001b[1;32m-> 1785\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1793\u001b[0m     )\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1795\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\prompts\\base.py:160\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m--> 160\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\prompts\\base.py:156\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    150\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    151\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(msg)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Input to PromptTemplate is missing variables {'job_description[experience]', 'job_description[description]', 'job_description[required_skills]', 'job_description[role]'}.  Expected: ['job_description[description]', 'job_description[experience]', 'job_description[required_skills]', 'job_description[role]', 'matched_skills', 'missing_skills', 'resume_text'] Received: ['resume_text', 'job_description', 'matched_skills', 'missing_skills']\\nNote: if you intended {job_description[experience]} to be part of the string and not a variable, please escape it with double curly braces like: '{{job_description[experience]}}'.\""
     ]
    }
   ],
   "source": [
    "# Create the resume enhancement prompt template\n",
    "resume_enhancement_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ###CONTEXT\n",
    "    Original Resume:\n",
    "    {resume_text}\n",
    "    \n",
    "    Job Description:\n",
    "    Role: {job_description[role]}\n",
    "    Experience Required: {job_description[experience]}\n",
    "    Required Skills: {job_description[required_skills]}\n",
    "    Description: {job_description[description]}\n",
    "    \n",
    "    Matched Skills: {matched_skills}\n",
    "    Missing Skills: {missing_skills}\n",
    "    \n",
    "    ###INSTRUCTION\n",
    "    You are an expert ATS optimization and resume writing specialist. Create a highly optimized \n",
    "    resume that perfectly matches this job description while maintaining truthfulness to the \n",
    "    original resume. Focus on:\n",
    "\n",
    "    1. Using relevant keywords and phrases from the job description\n",
    "    2. Quantifying achievements where possible\n",
    "    3. Using action verbs\n",
    "    4. Maintaining ATS-friendly formatting\n",
    "    5. Highlighting matching skills prominently\n",
    "    \n",
    "    Return the resume in the following JSON format:\n",
    "    {{\n",
    "        \"professional_summary\": \"summary text\",\n",
    "        \"skills\": [\"skill1\", \"skill2\"],\n",
    "        \"experience\": [\n",
    "            {{\n",
    "                \"title\": \"job title\",\n",
    "                \"company\": \"company name\",\n",
    "                \"duration\": \"duration\",\n",
    "                \"achievements\": [\"achievement1\", \"achievement2\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"education\": [\n",
    "            {{\n",
    "                \"degree\": \"degree name\",\n",
    "                \"institution\": \"institution name\",\n",
    "                \"year\": \"year\"\n",
    "            }}\n",
    "        ],\n",
    "        \"certifications\": [\"cert1\", \"cert2\"]\n",
    "    }}\n",
    "\n",
    "    ###RESPONSE (VALID JSON ONLY)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Now invoke the prompt with the correct variables\n",
    "resume_enhancement = resume_enhancement_prompt | llm\n",
    "res = resume_enhancement.invoke(input={\n",
    "    'resume_text': resume_text,\n",
    "    'job_description': job_description,\n",
    "    'matched_skills': ', '.join(matched_skills_list),\n",
    "    'missing_skills': ', '.join(missing_skills)\n",
    "})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f838acc-8485-427c-9bd7-138b1bf6ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AIResumeEnhancer:\n",
    "    def __init__(self, groq_api_key: str):\n",
    "        \"\"\"Initialize the resume enhancer with necessary components.\"\"\"\n",
    "        self.llm = ChatGroq(\n",
    "            model=\"llama-3.1-70b-versatile\",\n",
    "            groq_api_key=groq_api_key,\n",
    "            temperature=0.2,  # Lower temperature for more focused output\n",
    "            max_tokens=None\n",
    "        )\n",
    "        \n",
    "        # Prompt templates for different tasks\n",
    "        self.resume_enhancement_prompt = PromptTemplate.from_template(\n",
    "            \"\"\"\n",
    "            ###CONTEXT\n",
    "            Original Resume:\n",
    "            {resume_text}\n",
    "            \n",
    "            Job Description:\n",
    "            {job_description}\n",
    "            \n",
    "            Matched Skills: {matched_skills}\n",
    "            \n",
    "            ###INSTRUCTION\n",
    "            You are an expert ATS optimization and resume writing specialist. Create a highly optimized \n",
    "            resume that perfectly matches this job description while maintaining truthfulness to the \n",
    "            original resume. Focus on:\n",
    "\n",
    "            1. Using relevant keywords and phrases from the job description\n",
    "            2. Quantifying achievements where possible\n",
    "            3. Using action verbs\n",
    "            4. Maintaining ATS-friendly formatting\n",
    "            5. Highlighting matching skills prominently\n",
    "            \n",
    "            Return the resume in the following JSON format:\n",
    "            {\n",
    "                \"professional_summary\": \"summary text\",\n",
    "                \"skills\": [\"skill1\", \"skill2\"],\n",
    "                \"experience\": [\n",
    "                    {\n",
    "                        \"title\": \"job title\",\n",
    "                        \"company\": \"company name\",\n",
    "                        \"duration\": \"duration\",\n",
    "                        \"achievements\": [\"achievement1\", \"achievement2\"]\n",
    "                    }\n",
    "                ],\n",
    "                \"education\": [\n",
    "                    {\n",
    "                        \"degree\": \"degree name\",\n",
    "                        \"institution\": \"institution name\",\n",
    "                        \"year\": \"year\"\n",
    "                    }\n",
    "                ],\n",
    "                \"certifications\": [\"cert1\", \"cert2\"]\n",
    "            }\n",
    "\n",
    "            ###RESPONSE (VALID JSON ONLY)\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        self.ats_score_prompt = PromptTemplate.from_template(\n",
    "            \"\"\"\n",
    "            ###CONTEXT\n",
    "            Resume:\n",
    "            {resume_text}\n",
    "            \n",
    "            Job Description:\n",
    "            {job_description}\n",
    "            \n",
    "            ###INSTRUCTION\n",
    "            Analyze this resume's ATS optimization score and provide specific feedback.\n",
    "            Return response in the following JSON format:\n",
    "            {\n",
    "                \"ats_score\": \"score out of 100\",\n",
    "                \"keyword_match_rate\": \"percentage\",\n",
    "                \"missing_keywords\": [\"keyword1\", \"keyword2\"],\n",
    "                \"format_issues\": [\"issue1\", \"issue2\"],\n",
    "                \"improvement_suggestions\": [\"suggestion1\", \"suggestion2\"]\n",
    "            }\n",
    "\n",
    "            ###RESPONSE (VALID JSON ONLY)\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "    def enhance_resume(self, resume_text: str, job_description: str, matched_skills: List[str]) -> Dict:\n",
    "        \"\"\"Generate an enhanced version of the resume.\"\"\"\n",
    "        chain = self.resume_enhancement_prompt | self.llm\n",
    "        \n",
    "        response = chain.invoke({\n",
    "            'resume_text': resume_text,\n",
    "            'job_description': job_description,\n",
    "            'matched_skills': \", \".join(matched_skills)\n",
    "        })\n",
    "        \n",
    "        return json.loads(response.content)\n",
    "\n",
    "    def get_ats_score(self, resume_text: str, job_description: str) -> Dict:\n",
    "        \"\"\"Analyze the resume's ATS optimization score.\"\"\"\n",
    "        chain = self.ats_score_prompt | self.llm\n",
    "        \n",
    "        response = chain.invoke({\n",
    "            'resume_text': resume_text,\n",
    "            'job_description': job_description\n",
    "        })\n",
    "        \n",
    "        return json.loads(response.content)\n",
    "\n",
    "    def generate_docx(self, enhanced_resume: Dict) -> Document:\n",
    "        \"\"\"Generate a properly formatted DOCX file from the enhanced resume.\"\"\"\n",
    "        doc = Document()\n",
    "        \n",
    "        # Set margins\n",
    "        sections = doc.sections\n",
    "        for section in sections:\n",
    "            section.top_margin = Inches(0.5)\n",
    "            section.bottom_margin = Inches(0.5)\n",
    "            section.left_margin = Inches(0.5)\n",
    "            section.right_margin = Inches(0.5)\n",
    "\n",
    "        # Name and Contact (placeholder - you'd need to extract this from original resume)\n",
    "        name = doc.add_paragraph()\n",
    "        name_run = name.add_run(\"John Doe\")\n",
    "        name_run.bold = True\n",
    "        name_run.font.size = Pt(16)\n",
    "        name.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "        # Professional Summary\n",
    "        doc.add_heading('Professional Summary', level=1)\n",
    "        doc.add_paragraph(enhanced_resume['professional_summary'])\n",
    "\n",
    "        # Skills\n",
    "        doc.add_heading('Skills', level=1)\n",
    "        skills_para = doc.add_paragraph()\n",
    "        skills_para.add_run(', '.join(enhanced_resume['skills']))\n",
    "\n",
    "        # Experience\n",
    "        doc.add_heading('Professional Experience', level=1)\n",
    "        for exp in enhanced_resume['experience']:\n",
    "            p = doc.add_paragraph()\n",
    "            p.add_run(f\"{exp['title']} - {exp['company']}\").bold = True\n",
    "            p.add_run(f\"\\n{exp['duration']}\")\n",
    "            \n",
    "            for achievement in exp['achievements']:\n",
    "                doc.add_paragraph(achievement, style='List Bullet')\n",
    "\n",
    "        # Education\n",
    "        doc.add_heading('Education', level=1)\n",
    "        for edu in enhanced_resume['education']:\n",
    "            p = doc.add_paragraph()\n",
    "            p.add_run(f\"{edu['degree']} - {edu['institution']}\").bold = True\n",
    "            p.add_run(f\"\\n{edu['year']}\")\n",
    "\n",
    "        # Certifications\n",
    "        if enhanced_resume.get('certifications'):\n",
    "            doc.add_heading('Certifications', level=1)\n",
    "            for cert in enhanced_resume['certifications']:\n",
    "                doc.add_paragraph(cert, style='List Bullet')\n",
    "\n",
    "        return doc\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    resume_text = \"\"\"\n",
    "    [Your original resume text here]\n",
    "    \"\"\"\n",
    "    \n",
    "    job_description = \"\"\"\n",
    "    [Job description text here]\n",
    "    \"\"\"\n",
    "    \n",
    "    matched_skills = [\"Python\", \"Data Analysis\", \"Machine Learning\"]\n",
    "    \n",
    "    # Initialize enhancer\n",
    "    enhancer = AIResumeEnhancer(groq_api_key=\"your_api_key\")\n",
    "    \n",
    "    # Generate enhanced resume\n",
    "    enhanced_resume = enhancer.enhance_resume(resume_text, job_description, matched_skills)\n",
    "    \n",
    "    # Get ATS score and feedback\n",
    "    ats_analysis = enhancer.get_ats_score(resume_text, job_description)\n",
    "    \n",
    "    # Generate DOCX\n",
    "    doc = enhancer.generate_docx(enhanced_resume)\n",
    "    doc.save('enhanced_resume.docx')\n",
    "    \n",
    "    print(\"ATS Analysis:\", json.dumps(ats_analysis, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff5587-48ac-41f2-bf68-cd7f156dbbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b65054-7523-4967-ab90-562231c57e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e30fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
